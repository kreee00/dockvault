#!/usr/bin/env bash
# This script was generated by bashly 1.3.4 (https://bashly.dev)
# Modifying it manually is not recommended

# :wrapper.bash3_bouncer
if ((BASH_VERSINFO[0] < 4 || (BASH_VERSINFO[0] == 4 && BASH_VERSINFO[1] < 2))); then
  printf "bash version 4.2 or higher is required\n" >&2
  exit 1
fi

# :command.master_script

# :command.version_command
version_command() {
  echo "$version"
}

# :command.usage
dockvault_usage() {
  printf "dockvault - Automated Docker Volume Backup & Restore Tool\n\n"

  printf "%s\n" "Usage:"
  printf "  dockvault COMMAND\n"
  printf "  dockvault [COMMAND] --help | -h\n"
  printf "  dockvault --version | -v\n"
  echo
  # :command.usage_commands
  printf "%s\n" "Commands:"
  printf "  %s   List all Docker volumes on this host\n" "scan    "
  printf "  %s   Show the managed backup scripts hierarchy\n" "list    "
  printf "  %s   Visualize Google Drive folder structure\n" "tree    "
  printf "  %s   Wizard to create dedicated backup/restore scripts for a volume\n" "generate"
  printf "  %s   Trigger immediate backup for specific volumes or run all\n" "backup  "
  printf "  %s   Restore navigator to find and execute volume restoration scripts\n" "restore "
  printf "  %s   Manage the automatic scheduler (Systemd Timer)\n" "schedule"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    # :command.usage_options
    printf "%s\n" "Options:"

    # :command.usage_fixed_flags
    printf "  %s\n" "--help, -h"
    printf "    Show this help\n"
    echo
    printf "  %s\n" "--version, -v"
    printf "    Show version number\n"
    echo

    # :command.usage_environment_variables
    printf "%s\n" "Environment Variables:"

    # :environment_variable.usage
    printf "  %s\n" "DOCKVAULT_HOME"
    printf "    Base directory for scripts (default: $HOME/dockvault_scripts)\n"
    printf "    %s\n" "Default: $HOME/dockvault_scripts"
    echo

    # :environment_variable.usage
    printf "  %s\n" "DOCKVAULT_RCLONE_REMOTE"
    printf "    Name of the Rclone remote (default: dockvault_backup)\n"
    printf "    %s\n" "Default: dockvault_backup"
    echo

  fi
}

# :command.usage
dockvault_scan_usage() {
  printf "dockvault scan - List all Docker volumes on this host\n\n"

  printf "%s\n" "Usage:"
  printf "  dockvault scan\n"
  printf "  dockvault scan --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    # :command.usage_options
    printf "%s\n" "Options:"

    # :command.usage_fixed_flags
    printf "  %s\n" "--help, -h"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
dockvault_list_usage() {
  printf "dockvault list - Show the managed backup scripts hierarchy\n\n"

  printf "%s\n" "Usage:"
  printf "  dockvault list\n"
  printf "  dockvault list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    # :command.usage_options
    printf "%s\n" "Options:"

    # :command.usage_fixed_flags
    printf "  %s\n" "--help, -h"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
dockvault_tree_usage() {
  printf "dockvault tree - Visualize Google Drive folder structure\n\n"

  printf "%s\n" "Usage:"
  printf "  dockvault tree [PATH] [OPTIONS]\n"
  printf "  dockvault tree --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    # :command.usage_options
    printf "%s\n" "Options:"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "--detailed, -d"
    printf "    Show detailed view with latest backup timestamps\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "--help, -h"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "Arguments:"

    # :argument.usage
    printf "  %s\n" "PATH"
    printf "    Optional subfolder path to list\n"
    echo

  fi
}

# :command.usage
dockvault_generate_usage() {
  printf "dockvault generate - Wizard to create dedicated backup/restore scripts for a volume\n\n"

  printf "%s\n" "Usage:"
  printf "  dockvault generate [OPTIONS]\n"
  printf "  dockvault generate --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    # :command.usage_options
    printf "%s\n" "Options:"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "--dry-run"
    printf "    Preview the generation without writing files\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "--help, -h"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
dockvault_backup_usage() {
  printf "dockvault backup - Trigger immediate backup for specific volumes or run all\n\n"

  printf "%s\n" "Usage:"
  printf "  dockvault backup [OPTIONS]\n"
  printf "  dockvault backup --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    # :command.usage_options
    printf "%s\n" "Options:"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "--dry-run"
    printf "    Simulate the backup execution\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "--help, -h"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
dockvault_restore_usage() {
  printf "dockvault restore - Restore navigator to find and execute volume restoration scripts\n\n"

  printf "%s\n" "Usage:"
  printf "  dockvault restore\n"
  printf "  dockvault restore --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    # :command.usage_options
    printf "%s\n" "Options:"

    # :command.usage_fixed_flags
    printf "  %s\n" "--help, -h"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
dockvault_schedule_usage() {
  printf "dockvault schedule - Manage the automatic scheduler (Systemd Timer)\n\n"
  printf "Alias: cron\n"
  echo

  printf "%s\n" "Usage:"
  printf "  dockvault schedule [OPTIONS]\n"
  printf "  dockvault schedule --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    # :command.usage_options
    printf "%s\n" "Options:"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "--install, -i"
    printf "    Install and enable the Systemd timer (Runs daily)\n"
    echo

    # :flag.usage
    printf "  %s\n" "--check, -c"
    printf "    Check the status of the Systemd timer\n"
    echo

    # :flag.usage
    printf "  %s\n" "--logs, -l"
    printf "    View Systemd execution logs\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "--help, -h"
    printf "    Show this help\n"
    echo

    # :command.footer
    printf "WSL / WINDOWS USERS:\n--------------------\nSystemd and Cron often do not run reliably in the background on WSL.\n\nRecommended Method:\n1. Open 'Task Scheduler' in Windows.\n2. Create a Basic Task (Daily).\n3. Action: \"Start a Program\"\n4. Program: wsl.exe\n5. Arguments: -u <YOUR_USER> bash /home/<YOUR_USER>/dockvault_scripts/master_backup.sh\n\n"
    echo

  fi
}

# :command.normalize_input
# :command.normalize_input_function
normalize_input() {
  local arg passthru flags
  passthru=false

  while [[ $# -gt 0 ]]; do
    arg="$1"
    if [[ $passthru == true ]]; then
      input+=("$arg")
    elif [[ $arg =~ ^(--[a-zA-Z0-9_\-]+)=(.+)$ ]]; then
      input+=("${BASH_REMATCH[1]}")
      input+=("${BASH_REMATCH[2]}")
    elif [[ $arg =~ ^(-[a-zA-Z0-9])=(.+)$ ]]; then
      input+=("${BASH_REMATCH[1]}")
      input+=("${BASH_REMATCH[2]}")
    elif [[ $arg =~ ^-([a-zA-Z0-9][a-zA-Z0-9]+)$ ]]; then
      flags="${BASH_REMATCH[1]}"
      for ((i = 0; i < ${#flags}; i++)); do
        input+=("-${flags:i:1}")
      done
    elif [[ "$arg" == "--" ]]; then
      passthru=true
      input+=("$arg")
    else
      input+=("$arg")
    fi

    shift
  done
}

# :command.inspect_args
inspect_args() {
  local k

  if ((${#args[@]})); then
    readarray -t sorted_keys < <(printf '%s\n' "${!args[@]}" | sort)
    echo args:
    for k in "${sorted_keys[@]}"; do
      echo "- \${args[$k]} = ${args[$k]}"
    done
  else
    echo args: none
  fi

  if ((${#deps[@]})); then
    readarray -t sorted_keys < <(printf '%s\n' "${!deps[@]}" | sort)
    echo
    echo deps:
    for k in "${sorted_keys[@]}"; do
      echo "- \${deps[$k]} = ${deps[$k]}"
    done
  fi

  if ((${#env_var_names[@]})); then
    readarray -t sorted_names < <(printf '%s\n' "${env_var_names[@]}" | sort)
    echo
    echo "environment variables:"
    for k in "${sorted_names[@]}"; do
      echo "- \$$k = ${!k:-}"
    done
  fi
}

# :command.user_lib
# src/lib/tpl_common.sh
# ==============================================================================
# COMMON SCRIPT HEADERS & FOOTERS
# ==============================================================================

# $1 = volume_name
# $2 = template_type
tpl_header() {
    local vol="$1"
    local type="$2"

    cat <<EOF
#!/bin/bash
# ======================================================
# BACKUP SCRIPT for: $vol
# Type: $type
# Auto-generated by DockVault
# ======================================================

set -e

# Colors
cyan=\$(tput setaf 6)
green=\$(tput setaf 2)
yellow=\$(tput setaf 3)
reset=\$(tput sgr0)

TIMESTAMP=\$(date +"%Y%m%d_%H%M%S")
TEMP_DIR="/tmp/backup_${vol}_\$TIMESTAMP"
mkdir -p "\$TEMP_DIR"

echo "\${cyan}[1/4] Starting backup for $vol at \$(date)\${reset}"
EOF
}

# $1 = remote
# $2 = gdrive_path
tpl_backup_footer() {
    local remote="$1"
    local path="$2"

    cat <<EOF

if [ -f "\$TEMP_DIR/\$ARCHIVE_NAME" ]; then
  FILE_SIZE=\$(du -h "\$TEMP_DIR/\$ARCHIVE_NAME" | cut -f1)
  echo "\${green}[2/4] Compression Complete. Archive Size: \$FILE_SIZE\${reset}"

  echo "\${cyan}[3/4] Uploading to Google Drive ($remote:$path)...\${reset}"

  if rclone copy "\$TEMP_DIR/\$ARCHIVE_NAME" "$remote:$path" --progress; then
     echo ""
     echo "\${green}[SUCCESS] Uploaded: \$ARCHIVE_NAME\${reset}"
  else
     echo "\${red}[ERROR] Rclone upload failed.\${reset}"
     exit 1
  fi
  rm -rf "\$TEMP_DIR"
else
  echo "\${red}[ERROR] Backup creation failed, file not found.\${reset}"
  exit 1
fi
EOF
}

# $1 = remote
# $2 = gdrive_path
# $3 = retention_days (e.g. 30d)
# $4 = min_files_count (e.g. 30)
tpl_retention_logic() {
    local remote="$1"
    local path="$2"
    local age="$3"
    local min_count="$4"

    cat <<EOF

# ======================================================
# RETENTION POLICY CHECK
# ======================================================
echo "\${cyan}[4/4] Checking Retention Policy (Max Age: $age, Min Files: $min_count)...\${reset}"

# Count total files in the remote folder
TOTAL_FILES=\$(rclone lsf "$remote:$path" --files-only | wc -l)

echo "Total backup files found: \$TOTAL_FILES"

if [ "\$TOTAL_FILES" -gt "$min_count" ]; then
  echo "Threshold met (> $min_count files). Pruning files older than $age..."

  # Run deletion
  # --min-age 30d means "files created more than 30 days ago"
  rclone delete "$remote:$path" --min-age $age -v

  echo "\${green}[CLEANUP] Old backups pruned.\${reset}"
else
  echo "\${yellow}[SKIP] File count (\$TOTAL_FILES) is below threshold ($min_count). No deletion performed.\${reset}"
fi

echo ""
echo "\${green}Backup Job Complete.\${reset}"
EOF
}

# $1 = volume_name
# $2 = remote
# $3 = gdrive_path
# $4 = restore_logic_block
tpl_restore_script() {
    local vol="$1"
    local remote="$2"
    local path="$3"
    local logic="$4"

    cat <<EOF
#!/bin/bash
# ======================================================
# RESTORE SCRIPT for: $vol
# Auto-generated by DockVault
# ======================================================

# Colors
cyan=\$(tput setaf 6)
green=\$(tput setaf 2)
yellow=\$(tput setaf 3)
red=\$(tput setaf 1)
reset=\$(tput sgr0)

echo "\${cyan}== RESTORE WIZARD: $vol ==\${reset}"
echo "\${red}WARNING: This will OVERWRITE data in the volume/database.\${reset}"
echo ""

# 1. Ask for Remote Folder
DEFAULT_PATH="$path"
read -e -p "Confirm Backup Folder Path (Default: \$DEFAULT_PATH): " INPUT_PATH
REMOTE_FOLDER="\${INPUT_PATH:-\$DEFAULT_PATH}"

# Remove quotes
REMOTE_FOLDER="\${REMOTE_FOLDER%\"}"
REMOTE_FOLDER="\${REMOTE_FOLDER#\"}"

echo ""
echo "\${cyan}Fetching file list from: $remote:\$REMOTE_FOLDER...\${reset}"

# 2. List Files & Interactive Select
mapfile -t FILE_LIST < <(rclone lsf "$remote:\$REMOTE_FOLDER" --files-only | sort -r)

if [ \${#FILE_LIST[@]} -eq 0 ]; then
  echo "\${red}No files found in $remote:\$REMOTE_FOLDER\${reset}"
  exit 1
fi

echo "Available Backups (Newest First):"
i=0
for file in "\${FILE_LIST[@]}"; do
  i=\$((i+1))
  echo "  [\$i] \$file"
done

echo ""
read -p "\${yellow}Select file number to restore: \${reset}" SELECTION

if [[ "\$SELECTION" =~ ^[0-9]+$ ]] && [ "\$SELECTION" -ge 1 ] && [ "\$SELECTION" -le "\${#FILE_LIST[@]}" ]; then
  idx=\$((SELECTION-1))
  SELECTED_FILE="\${FILE_LIST[\$idx]}"
else
  echo "\${red}Invalid selection.\${reset}"
  exit 1
fi

FULL_REMOTE_PATH="\$REMOTE_FOLDER/\$SELECTED_FILE"

echo ""
echo "-------------------------------------"
echo "Source: $remote:\$FULL_REMOTE_PATH"
echo "Target: $vol"
echo "-------------------------------------"
read -p "Type 'RESTORE' to confirm: " confirm

if [ "\$confirm" != "RESTORE" ]; then
  echo "Aborted."
  exit 1
fi

TEMP_DIR="/tmp/restore_${vol}_\$(date +%s)"
mkdir -p "\$TEMP_DIR"

echo "\${cyan}[INFO] Downloading backup file...\${reset}"
if ! rclone copy "$remote:\$FULL_REMOTE_PATH" "\$TEMP_DIR" --progress; then
  echo "\${red}[ERROR] Download failed.\${reset}"
  exit 1
fi

LOCAL_FILE=\$(find "\$TEMP_DIR" -type f | head -n 1)
FILENAME=\$(basename "\$LOCAL_FILE")

# === SPECIFIC RESTORE LOGIC ===
$logic
# ==============================

rm -rf "\$TEMP_DIR"
echo "\${green}[SUCCESS] Restore finished.\${reset}"
EOF
}

# src/lib/tpl_mysql.sh
# $1 = volume_name, $2 = container, $3 = user, $4 = db_name, $5 = password
gen_backup_logic_mysql() {
    local vol="$1"
    local cont="$2"
    local user="$3"
    local db="$4"
    local pass="$5"

    cat <<EOF

ARCHIVE_NAME="${vol}_mysqldump_\${TIMESTAMP}.sql.gz"
echo "\${yellow}Dumping MySQL Database...\${reset}"

# We pass MYSQL_PWD env var to the container so mysqldump can authenticate
docker exec -e MYSQL_PWD='$pass' $cont mysqldump -u $user $db | gzip > "\$TEMP_DIR/\$ARCHIVE_NAME"
EOF
}

# $1 = container, $2 = user, $3 = db_name, $4 = password
gen_restore_logic_mysql() {
    local cont="$1"
    local user="$2"
    local db="$3"
    local pass="$4"

    cat <<EOF
echo "\${yellow}[INFO] Streaming SQL dump to MySQL...\${reset}"

# Using env var for password to avoid interactive prompt
if [[ "\$FILENAME" == *.gz ]]; then
  zcat "\$LOCAL_FILE" | docker exec -i -e MYSQL_PWD='$pass' $cont mysql -u $user $db
else
  cat "\$LOCAL_FILE" | docker exec -i -e MYSQL_PWD='$pass' $cont mysql -u $user $db
fi
EOF
}

# src/lib/tpl_postgres.sh
# $1 = volume_name, $2 = container, $3 = user, $4 = db_name, $5 = password
gen_backup_logic_postgres() {
    local vol="$1"
    local cont="$2"
    local user="$3"
    local db="$4"
    local pass="$5"

    cat <<EOF

ARCHIVE_NAME="${vol}_pgdump_\${TIMESTAMP}.sql.gz"
echo "\${yellow}Dumping PostgreSQL Database...\${reset}"

# We pass PGPASSWORD env var to the container so pg_dump authenticates automatically
docker exec -e PGPASSWORD='$pass' -t $cont pg_dump -U $user $db | gzip > "\$TEMP_DIR/\$ARCHIVE_NAME"
EOF
}

# $1 = container, $2 = user, $3 = db_name, $4 = password
gen_restore_logic_postgres() {
    local cont="$1"
    local user="$2"
    local db="$3"
    local pass="$4"

    cat <<EOF
echo "\${yellow}[INFO] Streaming SQL dump to PostgreSQL...\${reset}"

if [[ "\$FILENAME" == *.gz ]]; then
  zcat "\$LOCAL_FILE" | docker exec -i -e PGPASSWORD='$pass' $cont psql -U $user -d $db
else
  cat "\$LOCAL_FILE" | docker exec -i -e PGPASSWORD='$pass' $cont psql -U $user -d $db
fi
EOF
}

# src/lib/tpl_standard.sh
# $1 = volume_name
gen_backup_logic_standard() {
    local vol="$1"

    cat <<EOF

ARCHIVE_NAME="${vol}_\${TIMESTAMP}.tar.gz"
echo "Creating archive: \$ARCHIVE_NAME"

echo "\${yellow}Compressing files (Detailed Log):\${reset}"
# Using 'sh -c' to ensure wildcards work inside the container
docker run --rm \\
  -v ${vol}:/source:ro \\
  -v \$TEMP_DIR:/dest \\
  alpine sh -c "tar -czvf /dest/\$ARCHIVE_NAME -C /source ."
EOF
}

# $1 = volume_name
gen_restore_logic_standard() {
    local vol="$1"

    cat <<EOF
echo "\${yellow}[INFO] Wiping volume and extracting...\${reset}"
docker run --rm \\
  -v ${vol}:/target \\
  -v \$TEMP_DIR:/source \\
  alpine sh -c "cd /target && rm -rf ./* && tar -xzf /source/\$FILENAME -C /target"
EOF
}

# src/lib/utils.sh
green=$(tput setaf 2)
red=$(tput setaf 1)
yellow=$(tput setaf 3)
blue=$(tput setaf 4)
cyan=$(tput setaf 6)
reset=$(tput sgr0)

check_dependencies() {
  local dependencies=("docker" "rclone" "tar" "gzip")
  for cmd in "${dependencies[@]}"; do
    if ! command -v "$cmd" &> /dev/null; then
      echo "${red}Error: Required command '$cmd' is not installed.${reset}"
      exit 1
    fi
  done
}

select_volume() {
  echo "${blue}Scanning Docker volumes...${reset}" >&2
  local volumes=($(docker volume ls -q))
  if [ ${#volumes[@]} -eq 0 ]; then
    echo "${red}No docker volumes found!${reset}" >&2
    exit 1
  fi
  PS3="${yellow}Select target volume: ${reset}"
  select vol in "${volumes[@]}"; do
    if [[ -n "$vol" ]]; then echo "$vol"; break; fi
  done < /dev/tty
}

select_container() {
  echo "${blue}Scanning running containers...${reset}" >&2
  local containers=($(docker ps --format "{{.Names}}"))
  if [ ${#containers[@]} -eq 0 ]; then
    echo "${red}No running containers found!${reset}" >&2
    exit 1
  fi
  PS3="${yellow}Select container: ${reset}"
  select cont in "${containers[@]}"; do
    if [[ -n "$cont" ]]; then echo "$cont"; break; fi
  done < /dev/tty
}

update_master_script() {
  local master_file="${DOCKVAULT_HOME}/master_backup.sh"

  # specific script to register
  local new_script_path="$1"

  # Create master if not exists
  if [ ! -f "$master_file" ]; then
    cat <<EOF > "$master_file"
#!/bin/bash
# Master Backup Script - Managed by DockVault
# Add this file to crontab

LOG_DIR="${DOCKVAULT_HOME}/logs"
mkdir -p "\$LOG_DIR"
TODAY=\$(date +"%Y-%m-%d")
MASTER_LOG="\$LOG_DIR/master_\$TODAY.log"

echo "[START] Master Backup started at \$(date)" >> "\$MASTER_LOG"

EOF
    chmod +x "$master_file"
  fi

  # Check if entry exists to avoid duplicates
  if ! grep -Fq "$new_script_path" "$master_file"; then
    echo "bash \"$new_script_path\" >> \"\$MASTER_LOG\" 2>&1" >> "$master_file"
    echo "${green}Added to master_backup.sh${reset}"
  else
    echo "${yellow}Script already registered in master_backup.sh${reset}"
  fi
}

# :command.command_functions
# :command.function
dockvault_scan_command() {

  # src/scan_command.sh
  check_dependencies

  echo "${green}== Docker Volume Scan ==${reset}"

  # Define format for the table
  # %-30s = Left align, 30 chars wide
  # %-10s = Left align, 10 chars wide
  format="%-35s %-12s %s\n"

  printf "$format" "VOLUME NAME" "DRIVER" "USED BY CONTAINER(S)"
  printf "$format" "-----------" "------" "--------------------"

  # Iterate through all volumes
  # We read line by line: volume_name driver
  docker volume ls --format '{{.Name}} {{.Driver}}' | while read -r vol driver; do

      # Find containers using this volume
      # --filter volume=XYZ finds containers mounting that specific volume
      # paste -sd "," - joins multiple lines with a comma (e.g., "container1,container2")
      containers=$(docker ps -a --filter volume="$vol" --format '{{.Names}}' | paste -sd "," -)

      # If no container found, show a dash
      if [ -z "$containers" ]; then
          containers="${yellow}(dangling)${reset}"
      else
          containers="${cyan}${containers}${reset}"
      fi

      printf "$format" "$vol" "$driver" "$containers"
  done

  echo ""
  echo "${blue}Tip: Use 'dockvault generate' to backup one of these volumes.${reset}"

}

# :command.function
dockvault_list_command() {

  # src/list_command.sh
  # Visualizes the local workspace hierarchy exactly as requested

  echo "${green}== Managed Scripts Hierarchy ==${reset}"
  echo "${cyan}$DOCKVAULT_HOME/${reset}            <-- Root Workspace"

  # 1. Show Master Script
  if [ -f "$DOCKVAULT_HOME/master_backup.sh" ]; then
      echo "‚îú‚îÄ‚îÄ ${green}master_backup.sh${reset}                <-- The SINGLE script added to Crontab"
  else
      echo "‚îú‚îÄ‚îÄ ${red}master_backup.sh${reset}                <-- (Missing) Run generate to create"
  fi

  # 2. Show Logs Folder
  if [ -d "$DOCKVAULT_HOME/logs" ]; then
      echo "‚îú‚îÄ‚îÄ ${blue}logs/${reset}                           <-- Centralized logs for all backups"
  else
      echo "‚îú‚îÄ‚îÄ ${red}logs/${reset}                           <-- (Missing)"
  fi

  # 3. Iterate Volume Folders
  # We capture folders into an array to handle the "last element" logic if desired,
  # but for simplicity and consistency with the requested format, we use standard tree branches.

  found_volumes=0
  for d in "$DOCKVAULT_HOME"/*/; do
      dirname=$(basename "$d")

      # Skip logs folder as we already showed it
      if [ "$dirname" == "logs" ]; then
          continue
      fi

      if [ -d "$d" ]; then
          found_volumes=1
          echo "‚îî‚îÄ‚îÄ ${cyan}$dirname/${reset}                      <-- Dedicated folder for volume: $dirname"

          # Check Backup Script
          if [ -f "$d/backup.sh" ]; then
              echo "    ‚îú‚îÄ‚îÄ ${green}backup.sh${reset}                 <-- Specific backup logic"
          else
              echo "    ‚îú‚îÄ‚îÄ ${red}backup.sh${reset}                 <-- (Missing)"
          fi

          # Check Restore Script
          if [ -f "$d/restore.sh" ]; then
              echo "    ‚îî‚îÄ‚îÄ ${green}restore.sh${reset}                <-- Specific restore logic"
          else
              echo "    ‚îî‚îÄ‚îÄ ${red}restore.sh${reset}                <-- (Missing)"
          fi
      fi
  done

  if [ $found_volumes -eq 0 ]; then
      echo "‚îî‚îÄ‚îÄ (No volume folders found)"
  fi

  echo ""

}

# :command.function
dockvault_tree_command() {

  # src/tree_command.sh
  #!/bin/bash

  check_dependencies

  remote="${DOCKVAULT_RCLONE_REMOTE}"
  target_path="${args[path]}"
  detailed="${args[--detailed]}"

  # ==============================================================================
  # HELPER: Get Latest File Info
  # ==============================================================================
  get_latest_file() {
      local full_path="$1"
      # Sort by date/time descending and pick top 1
      local latest=$(rclone lsl "${remote}:${full_path}" --max-depth 1 2>/dev/null | sort -k2,3 -r | head -n 1)

      if [ -n "$latest" ]; then
          local size=$(echo "$latest" | awk '{print $1}')
          local date=$(echo "$latest" | awk '{print $2}')
          local time=$(echo "$latest" | awk '{print $3}' | cut -d. -f1)
          local name=$(echo "$latest" | cut -d' ' -f4-)

          # Human readable size
          if [ ${#size} -gt 6 ]; then
             size="$((${size}/1024/1024))MB"
          else
             size="$((${size}/1024))KB"
          fi

          echo "$name ($date $time | $size)"
      fi
  }

  # ==============================================================================
  # LOGIC: Standard Tree
  # ==============================================================================
  print_tree_standard() {
      local remote="$1"
      local current_path="$2"
      local indent="$3"
      local is_last="$4"

      local display_name=$(basename "$current_path")
      if [ -z "$display_name" ]; then
          display_name="/"
      fi

      if [ "$is_last" = "true" ]; then
          echo "${indent}‚îî‚îÄ‚îÄ üìÅ $display_name"
          indent="${indent}    "
      else
          echo "${indent}‚îú‚îÄ‚îÄ üìÅ $display_name"
          indent="${indent}‚îÇ   "
      fi

      local folders=()
      while IFS= read -r folder; do
          folders+=("$folder")
      done < <(rclone lsf "${remote}:${current_path}" --dirs-only --max-depth 1 2>/dev/null | grep -v '^$')

      local count=${#folders[@]}
      local i=0
      for folder in "${folders[@]}"; do
          i=$((i + 1))
          local is_last_child="false"
          if [ $i -eq $count ]; then
              is_last_child="true"
          fi

          folder=$(echo "$folder" | sed 's|/$||')
          print_tree_standard "$remote" "${current_path%/}/${folder}" "$indent" "$is_last_child"
      done
  }

  # ==============================================================================
  # LOGIC: Detailed Tree (FIXED VERSION)
  # ==============================================================================
  print_tree_detailed() {
      local remote="$1"
      local current_path="$2"
      local indent="$3"
      local is_last="$4"
      local depth="$5"

      local display_name=$(basename "$current_path")
      if [ -z "$display_name" ]; then
          display_name="/"
      fi

      # Print folder with appropriate tree characters
      if [ "$is_last" = "true" ]; then
          echo "${indent}‚îî‚îÄ‚îÄ üìÅ ${cyan}$display_name${reset}"
          child_indent="${indent}    "
      else
          echo "${indent}‚îú‚îÄ‚îÄ üìÅ ${cyan}$display_name${reset}"
          child_indent="${indent}‚îÇ   "
      fi

      # Get subfolders
      local folders=()
      while IFS= read -r folder; do
          folders+=("$folder")
      done < <(rclone lsf "${remote}:${current_path}" --dirs-only --max-depth 1 2>/dev/null | grep -v '^$')

      local count=${#folders[@]}

      # If no subfolders, check for files and show latest
      if [ $count -eq 0 ]; then
          local latest_file_info=$(get_latest_file "$current_path")
          if [ -n "$latest_file_info" ]; then
              # Check if there are any files at all
              local file_count=$(rclone lsf "${remote}:${current_path}" --max-depth 1 2>/dev/null | grep -v '/$' | wc -l)
              if [ $file_count -gt 0 ]; then
                  # Show latest file with proper tree character
                  if [ "$is_last" = "true" ]; then
                      echo "${child_indent}‚îî‚îÄ‚îÄ ${green}üìÑ Latest: $latest_file_info${reset}"
                  else
                      echo "${child_indent}‚îú‚îÄ‚îÄ ${green}üìÑ Latest: $latest_file_info${reset}"
                  fi

                  # If there are more than 1 files, show count
                  if [ $file_count -gt 1 ]; then
                      if [ "$is_last" = "true" ]; then
                          echo "${child_indent}    ‚îî‚îÄ‚îÄ ${yellow}... and $((file_count - 1)) more file(s)${reset}"
                      else
                          echo "${child_indent}‚îÇ   ‚îî‚îÄ‚îÄ ${yellow}... and $((file_count - 1)) more file(s)${reset}"
                      fi
                  fi
              else
                  # No files found, show empty
                  if [ "$is_last" = "true" ]; then
                      echo "${child_indent}‚îî‚îÄ‚îÄ ${yellow}(empty)${reset}"
                  else
                      echo "${child_indent}‚îú‚îÄ‚îÄ ${yellow}(empty)${reset}"
                  fi
              fi
          fi
      else
          # Process subfolders recursively
          local i=0
          for folder in "${folders[@]}"; do
              i=$((i + 1))
              local is_last_child="false"
              if [ $i -eq $count ]; then
                  is_last_child="true"
              fi

              folder=$(echo "$folder" | sed 's|/$||')
              print_tree_detailed "$remote" "${current_path%/}/${folder}" "$child_indent" "$is_last_child" "$((depth + 1))"
          done
      fi
  }

  # ==============================================================================
  # EXECUTION ENTRY POINT
  # ==============================================================================

  # Start the tree from target_path
  if [ -z "$target_path" ]; then
      target_path=""
  fi

  # Clean target path - remove trailing slashes
  target_path=$(echo "$target_path" | sed 's|/*$||')

  if [[ "$detailed" == "1" ]]; then
      echo "${green}== Detailed Remote View ($remote) ==${reset}"
      echo "Fetching details (this may take a moment)..."
      echo ""

      # Print the remote root
      if [ -z "$target_path" ]; then
          echo "üìÅ ${remote}:/"
      else
          echo "üìÅ ${remote}:${target_path}"
      fi

      # Get immediate children of the root
      folders=()
      while IFS= read -r folder; do
          folders+=("$folder")
      done < <(rclone lsf "${remote}:${target_path}" --dirs-only --max-depth 1 2>/dev/null | grep -v '^$')

      # Process each folder under root
      count=${#folders[@]}
      i=0
      for folder in "${folders[@]}"; do
          i=$((i + 1))
          is_last="false"
          if [ $i -eq $count ]; then
              is_last="true"
          fi

          folder=$(echo "$folder" | sed 's|/$||')
          print_tree_detailed "$remote" "${target_path%/}/${folder}" "" "$is_last" "1"
      done

      # Handle case where target path has no subfolders (it's a leaf directory)
      if [ ${#folders[@]} -eq 0 ]; then
          latest_file_info=$(get_latest_file "$target_path")
          if [ -n "$latest_file_info" ]; then
              local file_count=$(rclone lsf "${remote}:${target_path}" --max-depth 1 2>/dev/null | grep -v '/$' | wc -l)
              if [ $file_count -gt 0 ]; then
                  echo "‚îî‚îÄ‚îÄ ${green}üìÑ Latest: $latest_file_info${reset}"
                  if [ $file_count -gt 1 ]; then
                      echo "    ‚îî‚îÄ‚îÄ ${yellow}... and $((file_count - 1)) more file(s)${reset}"
                  fi
              fi
          fi
      fi

  else
      echo "${green}== Remote Tree View ($remote) ==${reset}"
      echo "Fetching structure..."
      echo ""

      # Print the remote root
      if [ -z "$target_path" ]; then
          echo "üìÅ ${remote}:/"
      else
          echo "üìÅ ${remote}:${target_path}"
      fi

      # Get immediate children of the root
      folders=()
      while IFS= read -r folder; do
          folders+=("$folder")
      done < <(rclone lsf "${remote}:${target_path}" --dirs-only --max-depth 1 2>/dev/null | grep -v '^$')

      # Process each folder under root
      count=${#folders[@]}
      i=0
      for folder in "${folders[@]}"; do
          i=$((i + 1))
          is_last="false"
          if [ $i -eq $count ]; then
              is_last="true"
          fi

          folder=$(echo "$folder" | sed 's|/$||')
          print_tree_standard "$remote" "${target_path%/}/${folder}" "" "$is_last"
      done

      echo ""
      echo "${blue}Tip: Use 'dockvault tree --detailed' to see backup file info.${reset}"
  fi

  echo ""

}

# :command.function
dockvault_generate_command() {

  # src/generate_command.sh
  check_dependencies

  echo "${green}== Script Generation Wizard ==${reset}"

  # 1. Inputs
  selected_vol=$(select_volume)
  echo "Selected Volume: ${green}$selected_vol${reset}"

  echo ""
  echo "Select Backup Template:"
  options=("Standard (Files)" "PostgreSQL (pg_dump)" "MySQL (mysqldump)")
  template_type=""
  PS3="${yellow}Choose type: ${reset}"
  select opt in "${options[@]}"; do
    case $opt in
      "Standard (Files)") template_type="standard"; break ;;
      "PostgreSQL (pg_dump)") template_type="postgres"; break ;;
      "MySQL (mysqldump)") template_type="mysql"; break ;;
      *) echo "${red}Invalid option${reset}" ;;
    esac
  done

  # DB Inputs
  db_user=""
  db_pass=""
  db_name=""
  db_container=""

  if [[ "$template_type" != "standard" ]]; then
    echo ""
    echo "${blue}Database Configuration:${reset}"
    echo "Select the running container:"
    db_container=$(select_container)

    read -p "Enter Database User: " db_user
    # -s hides the input for security
    read -s -p "Enter Database Password: " db_pass
    echo "" # Newline after silent input
    read -p "Enter Database Name: " db_name
  fi

  # DETERMINE JOB ID / FOLDER NAME
  job_name="$selected_vol"
  if [[ -n "$db_name" ]]; then
      safe_db_name=$(echo "$db_name" | tr -dc '[:alnum:]\-\_')
      job_name="${selected_vol}-${safe_db_name}"
  fi

  echo ""
  read -p "Enter Google Drive Upload Path (e.g. backups/production): " gdrive_path
  remote="${DOCKVAULT_RCLONE_REMOTE}"

  # 2. Paths
  vol_dir="${DOCKVAULT_HOME}/${job_name}"
  backup_script="${vol_dir}/backup.sh"
  restore_script="${vol_dir}/restore.sh"

  if [[ -d "$vol_dir" ]] && { [[ -f "$backup_script" ]] || [[ -f "$restore_script" ]]; }; then
    echo ""
    echo "${red}WARNING: Scripts for job '$job_name' already exist!${reset}"
    read -p "${yellow}Do you want to OVERWRITE them? (y/N): ${reset}" choice
    case "$choice" in

      y|Y ) echo "Overwriting...";;
      * ) echo "Cancelled."; exit 0;;
    esac
  fi

  if [[ "${args[--dry-run]}" != "1" ]]; then
    mkdir -p "$vol_dir"
  fi

  # ======================================================
  # GENERATE CONTENT
  # ======================================================

  # Start with Header
  b_content=$(tpl_header "$job_name" "$template_type")

  # Append Specific Logic based on type
  if [[ "$template_type" == "standard" ]]; then
      b_content+=$(gen_backup_logic_standard "$selected_vol")
      r_logic=$(gen_restore_logic_standard "$selected_vol")

  elif [[ "$template_type" == "postgres" ]]; then
      # Pass db_pass to the function
      b_content+=$(gen_backup_logic_postgres "$job_name" "$db_container" "$db_user" "$db_name" "$db_pass")
      r_logic=$(gen_restore_logic_postgres "$db_container" "$db_user" "$db_name" "$db_pass")

  elif [[ "$template_type" == "mysql" ]]; then
      # Pass db_pass to the function
      b_content+=$(gen_backup_logic_mysql "$job_name" "$db_container" "$db_user" "$db_name" "$db_pass")
      r_logic=$(gen_restore_logic_mysql "$db_container" "$db_user" "$db_name" "$db_pass")
  fi

  # Append Footer
  b_content+=$(tpl_backup_footer "$remote" "$gdrive_path")

  # Append Retention Policy
  b_content+=$(tpl_retention_logic "$remote" "$gdrive_path" "30d" "30")

  # Generate Full Restore Script
  r_content=$(tpl_restore_script "$job_name" "$remote" "$gdrive_path" "$r_logic")

  # ======================================================
  # WRITE OR PREVIEW
  # ======================================================
  if [[ "${args[--dry-run]}" == "1" ]]; then
    echo "${blue}--- PREVIEW: backup.sh ---${reset}"
    echo "$b_content"
    echo ""
    echo "${blue}--- PREVIEW: restore.sh ---${reset}"
    echo "$r_content"
  else
    # Write
    echo "$b_content" > "$backup_script"
    chmod +x "$backup_script"

    echo "$r_content" > "$restore_script"
    chmod +x "$restore_script"

    echo "${green}Generated scripts in: $vol_dir${reset}"
    update_master_script "$backup_script"
  fi
}

# :command.function
dockvault_backup_command() {

  # src/backup_command.sh
  check_dependencies

  echo "${green}== Manual Backup Trigger ==${reset}"
  echo "Workspace: $DOCKVAULT_HOME"

  # 1. Find Managed Volumes
  managed_vols=()
  for d in "$DOCKVAULT_HOME"/*/; do
    # Check if directory and contains backup.sh
    if [ -f "$d/backup.sh" ]; then
      managed_vols+=("$(basename "$d")")
    fi
  done

  if [ ${#managed_vols[@]} -eq 0 ]; then
    echo "${red}No managed backup scripts found.${reset}"
    echo "Use 'dockvault generate' to setup a volume first."
    exit 1
  fi

  # 2. Display Options
  echo ""
  echo "Available Backup Jobs:"
  i=0
  for vol in "${managed_vols[@]}"; do
    i=$((i + 1))
    echo "  [$i] $vol"
  done
  echo "  [A] Run ALL (Master Backup)"
  echo ""

  # 3. Capture Input
  read -p "${yellow}Enter selection (e.g. '1 3' for multiple, or 'A' for all): ${reset}" selection

  # 4. Process Selection
  selected_scripts=()
  run_master=false

  # Convert input to array (space separated)
  read -ra INDICES <<< "$selection"

  for idx in "${INDICES[@]}"; do
    if [[ "$idx" == "A" ]] || [[ "$idx" == "a" ]]; then
      run_master=true
      break
    elif [[ "$idx" =~ ^[0-9]+$ ]]; then
      # Adjust for 0-based array vs 1-based display
      array_idx=$((idx - 1))

      if [ $array_idx -ge 0 ] && [ $array_idx -lt ${#managed_vols[@]} ]; then
        vol_name="${managed_vols[$array_idx]}"
        selected_scripts+=("$DOCKVAULT_HOME/$vol_name/backup.sh")
      else
        echo "${red}Warning: Invalid index '$idx' ignored.${reset}"
      fi
    else
      echo "${red}Warning: Invalid input '$idx' ignored.${reset}"
    fi
  done

  # 5. Execute
  echo ""
  echo "${blue}--- Execution Plan ---${reset}"

  if [ "$run_master" = true ]; then
    master_script="$DOCKVAULT_HOME/master_backup.sh"
    if [ ! -f "$master_script" ]; then
      echo "${red}Error: Master script not found at $master_script${reset}"
      exit 1
    fi

    echo "Target: MASTER BACKUP (All Volumes)"

    if [[ "${args[--dry-run]}" == "1" ]]; then
      echo "${cyan}[DRY-RUN] Would execute: bash $master_script${reset}"
    else
      echo "Launching Master Backup..."
      echo "------------------------------------------------"
      bash "$master_script"
    fi

  elif [ ${#selected_scripts[@]} -gt 0 ]; then
    echo "Targets: ${#selected_scripts[@]} volume(s)"

    for script in "${selected_scripts[@]}"; do
      if [[ "${args[--dry-run]}" == "1" ]]; then
        echo "${cyan}[DRY-RUN] Would execute: bash $script${reset}"
      else
        echo "Running: $(basename "$(dirname "$script")") ..."
        bash "$script"
        echo "------------------------------------------------"
      fi
    done
  else
    echo "No valid selection made. Aborting."
    exit 0
  fi

  if [[ "${args[--dry-run]}" != "1" ]]; then
    echo ""
    echo "${green}Batch Completed.${reset}"
  fi

}

# :command.function
dockvault_restore_command() {

  # src/restore_command.sh
  check_dependencies

  echo "${green}== Restore Navigator ==${reset}"
  echo "Searching for managed restore scripts in $DOCKVAULT_HOME..."

  # Find folders that contain restore.sh
  managed_vols=()
  for d in "$DOCKVAULT_HOME"/*/; do
    if [ -f "$d/restore.sh" ]; then
      managed_vols+=("$(basename "$d")")
    fi
  done

  if [ ${#managed_vols[@]} -eq 0 ]; then
    echo "${red}No generated restore scripts found.${reset}"
    echo "Use 'dockvault generate' first to set up scripts."
    exit 1
  fi

  # Let user pick volume
  PS3="${yellow}Select volume to restore: ${reset}"
  select vol in "${managed_vols[@]}"; do
    if [[ -n "$vol" ]]; then
      script_path="$DOCKVAULT_HOME/$vol/restore.sh"
      echo "Launching: $script_path"
      echo "------------------------------------------------"
      bash "$script_path"
      break
    else
      echo "${red}Invalid selection.${reset}"
    fi
  done < /dev/tty

}

# :command.function
dockvault_schedule_command() {

  # src/schedule_command.sh
  check_dependencies

  SERVICE_NAME="dockvault-backup"
  SYSTEMD_SYSTEM_DIR="/etc/systemd/system"

  # Get the REAL user if running as sudo, otherwise use current user
  TARGET_USER="${SUDO_USER:-$USER}"
  TARGET_HOME=$(getent passwd "$TARGET_USER" | cut -d: -f6)
  REAL_MASTER_SCRIPT="$TARGET_HOME/dockvault_scripts/master_backup.sh"
  LOG_DIR="$TARGET_HOME/dockvault_scripts/logs"

  echo "${green}== Systemd Scheduler Manager (System-Wide) ==${reset}"

  if [ ! -f "$REAL_MASTER_SCRIPT" ]; then
    echo "${red}Error: Master script not found at ${REAL_MASTER_SCRIPT}.${reset}"
    echo "Run 'dockvault generate' first to initialize the workspace for user '$TARGET_USER'."
    exit 1
  fi

  # ======================================================
  # CHECK STATUS
  # ======================================================
  check_status() {
    # Check system-wide timers (requires sudo usually, but list-timers might show all)
    if systemctl list-timers --all 2>/dev/null | grep -q "$SERVICE_NAME"; then
      echo "${green}Status: ACTIVE (System-Wide)${reset}"
      echo ""
      echo "--- Timer Info ---"
      systemctl list-timers --no-pager | grep "$SERVICE_NAME"
      echo ""
      echo "--- Service Status ---"
      systemctl status "${SERVICE_NAME}.timer" --no-pager | head -n 10
    else
      echo "${yellow}Status: NOT INSTALLED${reset}"
    fi
  }

  # ======================================================
  # INSTALL LOGIC
  # ======================================================
  install_system_wide() {
    # Check for sudo/root permissions
    if [ "$EUID" -ne 0 ]; then
      echo "${red}Error: Installing system-wide services requires root privileges.${reset}"
      echo "Please run this command with sudo:"
      echo "  sudo dockvault schedule --install"
      exit 1
    fi

    echo "Setting up System-Wide Systemd Timer..."

    # Get the REAL user if running as sudo
    # If SUDO_USER is set, use it; otherwise use current USER
    TARGET_USER="${SUDO_USER:-$USER}"

    # We need the absolute path to the user's home if running as sudo
    # getent passwd $TARGET_USER | cut -d: -f6 -> returns /home/username
    TARGET_HOME=$(getent passwd "$TARGET_USER" | cut -d: -f6)

    # Re-evaluate DOCKVAULT_HOME based on target user if it points to /root
    # (This handles the case where sudo dockvault was run, confusing $HOME)
    REAL_MASTER_SCRIPT="$TARGET_HOME/dockvault_scripts/master_backup.sh"
    LOG_DIR="$TARGET_HOME/dockvault_scripts/logs"

    if [ ! -f "$REAL_MASTER_SCRIPT" ]; then
       echo "${red}Error: Could not locate master script at $REAL_MASTER_SCRIPT${reset}"
       echo "Ensure you generated the scripts as user '$TARGET_USER' first."
       exit 1
    fi

    # 1. Create Service File in /etc/systemd/system
    SERVICE_FILE="$SYSTEMD_SYSTEM_DIR/${SERVICE_NAME}.service"
    echo "Writing service file to: $SERVICE_FILE"

    cat <<EOF > "$SERVICE_FILE"
[Unit]
Description=DockVault Master Backup Service (User: $TARGET_USER)
After=network-online.target docker.service
Requires=docker.service

[Service]
Type=simple
User=$TARGET_USER
Environment="DOCKVAULT_HOME=$TARGET_HOME/dockvault_scripts"
ExecStart=/bin/bash $REAL_MASTER_SCRIPT
StandardOutput=append:$LOG_DIR/systemd_stdout.log
StandardError=append:$LOG_DIR/systemd_stderr.log

[Install]
WantedBy=multi-user.target
EOF

    # 2. Create Timer File
    TIMER_FILE="$SYSTEMD_SYSTEM_DIR/${SERVICE_NAME}.timer"
    echo "Writing timer file to: $TIMER_FILE"

    cat <<EOF > "$TIMER_FILE"
[Unit]
Description=Run DockVault Backup Daily

[Timer]
OnCalendar=*-*-* 01:00:00
Persistent=true

[Install]
WantedBy=timers.target
EOF

    # 3. Activate Changes
    echo "Reloading system daemon..."
    systemctl daemon-reload

    echo "Enabling and Starting timer..."
    systemctl enable --now "${SERVICE_NAME}.timer"

    if [ $? -eq 0 ]; then
        echo ""
        echo "${green}Success! System-wide timer is active.${reset}"
        echo "Runs as user: ${cyan}$TARGET_USER${reset}"
        echo "Script path:  ${cyan}$REAL_MASTER_SCRIPT${reset}"
        echo ""
        echo "${cyan}Next run:${reset} $(systemctl list-timers --no-pager | grep "$SERVICE_NAME" | awk '{print $2, $3}')"
    else
        echo "${red}Failed to enable timer.${reset}"
        exit 1
    fi
  }

  # ======================================================
  # VIEW LOGS
  # ======================================================
  view_logs() {
    echo "${blue}Fetching system logs for service...${reset}"
    # System logs usually require sudo to view fully, or being in 'systemd-journal' group
    journalctl -u "$SERVICE_NAME" -n 20 --no-pager || echo "${yellow}Permission denied. Try running with sudo.${reset}"
  }

  # ======================================================
  # EXECUTION
  # ======================================================

  if [[ "${args[--install]}" == "1" ]]; then
    install_system_wide
  elif [[ "${args[--logs]}" == "1" ]]; then
    view_logs
  elif [[ "${args[--check]}" == "1" ]]; then
    check_status
  else
    check_status

    # Check for WSL (Windows Subsystem for Linux)
    if grep -qi "microsoft" /proc/version 2>/dev/null; then
        echo "${yellow}Note: WSL detected. Systemd support requires WSL2 and recent updates.${reset}"
    fi

    if ! systemctl list-timers --all 2>/dev/null | grep -q "$SERVICE_NAME"; then
        echo ""
        echo "Timer not found."
        echo "To install system-wide, run:"
        echo "${cyan}sudo dockvault schedule --install${reset}"
    fi
  fi
}

# :command.parse_requirements
parse_requirements() {
  local key

  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --version | -v)
        version_command
        exit
        ;;

      --help | -h)
        long_usage=yes
        dockvault_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.environment_variables_filter
  # :command.environment_variables_default
  export DOCKVAULT_HOME="${DOCKVAULT_HOME:-$HOME/dockvault_scripts}"
  export DOCKVAULT_RCLONE_REMOTE="${DOCKVAULT_RCLONE_REMOTE:-dockvault_backup}"

  env_var_names+=("DOCKVAULT_HOME")
  env_var_names+=("DOCKVAULT_RCLONE_REMOTE")

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    scan)
      action="scan"
      shift
      dockvault_scan_parse_requirements "$@"
      shift $#
      ;;

    list)
      action="list"
      shift
      dockvault_list_parse_requirements "$@"
      shift $#
      ;;

    tree)
      action="tree"
      shift
      dockvault_tree_parse_requirements "$@"
      shift $#
      ;;

    generate)
      action="generate"
      shift
      dockvault_generate_parse_requirements "$@"
      shift $#
      ;;

    backup)
      action="backup"
      shift
      dockvault_backup_parse_requirements "$@"
      shift $#
      ;;

    restore)
      action="restore"
      shift
      dockvault_restore_parse_requirements "$@"
      shift $#
      ;;

    schedule | cron)
      action="schedule"
      shift
      dockvault_schedule_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      dockvault_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
dockvault_scan_parse_requirements() {
  local key

  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        dockvault_scan_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="scan"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
dockvault_list_parse_requirements() {
  local key

  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        dockvault_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
dockvault_tree_parse_requirements() {
  local key

  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        dockvault_tree_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tree"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --detailed | -d)

        # :flag.case_no_arg
        args['--detailed']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['path']+x} ]]; then
          args['path']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
dockvault_generate_parse_requirements() {
  local key

  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        dockvault_generate_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="generate"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --dry-run)

        # :flag.case_no_arg
        args['--dry-run']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
dockvault_backup_parse_requirements() {
  local key

  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        dockvault_backup_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="backup"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --dry-run)

        # :flag.case_no_arg
        args['--dry-run']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
dockvault_restore_parse_requirements() {
  local key

  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        dockvault_restore_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="restore"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
dockvault_schedule_parse_requirements() {
  local key

  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        dockvault_schedule_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schedule"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --install | -i)

        # :flag.case_no_arg
        args['--install']=1
        shift
        ;;

      # :flag.case
      --check | -c)

        # :flag.case_no_arg
        args['--check']=1
        shift
        ;;

      # :flag.case
      --logs | -l)

        # :flag.case_no_arg
        args['--logs']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.initialize
initialize() {
  declare -g version="3.8.0"
  set -e

  # :command.environment_variables_default
  export DOCKVAULT_HOME="${DOCKVAULT_HOME:-$HOME/dockvault_scripts}"
  export DOCKVAULT_RCLONE_REMOTE="${DOCKVAULT_RCLONE_REMOTE:-dockvault_backup}"

  # src/initialize.sh
  # Set up workspace
  export DOCKVAULT_HOME="${DOCKVAULT_HOME:-$HOME/dockvault_scripts}"
  mkdir -p "$DOCKVAULT_HOME"
  mkdir -p "$DOCKVAULT_HOME/logs"

  # Ensure PATH
  export PATH=$PATH:/usr/local/bin:/usr/bin:/bin

}

# :command.run
run() {
  # :command.globals
  declare -g long_usage=''
  declare -g -A args=()
  declare -g -A deps=()
  declare -g -a env_var_names=()
  declare -g -a input=()

  normalize_input "$@"
  parse_requirements "${input[@]}"

  case "$action" in
    "scan") dockvault_scan_command ;;
    "list") dockvault_list_command ;;
    "tree") dockvault_tree_command ;;
    "generate") dockvault_generate_command ;;
    "backup") dockvault_backup_command ;;
    "restore") dockvault_restore_command ;;
    "schedule") dockvault_schedule_command ;;
  esac
}

if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
  # :command.start
  command_line_args=("$@")
  initialize
  run "${command_line_args[@]}"
fi
